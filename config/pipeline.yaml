# config/pipeline.yaml

# 1. Where your raw sequencing reads live
reads_dir: "/path/to/raw_reads"

# 2. Taxonomy spreadsheet (Excel .xlsx or .csv BOLD format)
taxonomy_file: "/path/to/your_taxonomy.xlsx" 
taxonomy_sheet:   "Taxonomy" #Taxonomy sheet of the spreadsheet

# 3. Reference database (FASTA of SSU, ITS, LSU sequences) # ref_fasta is auto-downloaded if unset
ref_fasta: "" 

# 4. Trimming
skip_trimming:   false # if true, will *NOT* run fastp but use the input fastq

# 5. coverage check
auto_subsample: true       # always check coverage and subsample if needed
max_coverage: 150          # threshold (×) above which to downsample (default: 100)
target_coverage: 100       # aim (×) when subsampling (default: 90)
mapq: 0                    # minimum mapping quality (default: 0)

# 6. Assembler
assembler: spades    # change to "spades" to run SPAdes, or "megahit" to run MEGAHIT

# 7. Soft-clipped read filtering
filter_softclipped_reads: false # or true
min_softclip_bases: 20 # 'auto' or integer soft-clip length cutoff
softclip_filter_mode: trim  # or "full"

# 8. Computational resources
threads: 8       # e.g. number of CPU cores to use
mem_gb: 16       # e.g. total RAM in GB

# 9. Where to put all output
outdir: "results"
